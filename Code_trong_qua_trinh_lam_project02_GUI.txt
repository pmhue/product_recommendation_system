
import streamlit as st
import pandas as pd
import pickle
import os

def install_missing_packages():
    import subprocess
    import sys
    
    try:
        import surprise
    except ImportError:
        st.warning("Installing required package 'scikit-surprise'. Please wait...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "scikit-surprise"])
        st.success("Package installed successfully! Please restart the app.")
        st.stop()

install_missing_packages()
import surprise
from surprise import Dataset, SVDpp
from surprise.model_selection import train_test_split
from surprise.model_selection import cross_validate
import pandas as pd
import numpy as np
from datetime import datetime
from surprise import Reader, Dataset, SVD, SVDpp, NMF, SlopeOne, KNNBasic, KNNBaseline, KNNWithMeans, KNNWithZScore, CoClustering, BaselineOnly
from surprise.model_selection.validation import cross_validate

from datetime import datetime

import streamlit as st
import pandas as pd
import pickle
import os
import random


# T·∫£i d·ªØ li·ªáu
data_test = pd.read_csv('./df_summary_collaborative.csv')
df_products = pd.read_csv('./San_pham.csv')

# T·∫£i m√¥ h√¨nh SVD++
model_path = './svdpp_model.pkl'
if not os.path.exists(model_path):
    st.error("Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh SVD++. Vui l√≤ng ƒë·∫£m b·∫£o m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i 'model/svdpp_model.pkl'.")
else:
    with open(model_path, 'rb') as f:
        loaded_svd_pp = pickle.load(f)
    # st.success("M√¥ h√¨nh SVD++ ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
    # st.success("Ch√†o m·ª´ng c√°c b·∫°n ƒë√£ gh√© thƒÉm h·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m c·ªßa Hasaki.vn!")
    # Th√™m hi·ªáu ·ª©ng ch·∫°y ch·ªØ t·ª´ tr√°i qua ph·∫£i v√† in nghi√™ng
    st.markdown(
        """
        <style>
        @keyframes slide-in {
            0% {
                transform: translateX(-100%);
            }
            100% {
                transform: translateX(0);
            }
        }
        .welcome-text {
            font-style: italic;
            font-size: 20px;
            color: #5271C4;
            animation: slide-in 3s ease-in-out;
            white-space: nowrap;
            overflow: hidden;
        }
        </style>
        <div class="welcome-text">
            Ch√†o m·ª´ng c√°c b·∫°n ƒë√£ gh√© thƒÉm h·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m c·ªßa Hasaki.vn!
        </div>
        """,
        unsafe_allow_html=True
    )


# H√†m g·ª£i √Ω s·∫£n ph·∫©m d·ª±a tr√™n m√£ kh√°ch h√†ng
def recommend_products_with_scores(customer_id, df_products, model, top_n=4, rating=None):
    all_products = df_products['ma_san_pham'].unique()
    rated_products = df_products[df_products['ma_khach_hang'] == customer_id]['ma_san_pham'].unique()
    products_to_predict = [prod for prod in all_products if prod not in rated_products]

    recommendations = []
    for product_id in products_to_predict:
        prediction = model.predict(customer_id, product_id)
        recommendations.append((product_id, prediction.est))

    recommended_products = pd.DataFrame(recommendations, columns=['ma_san_pham', 'predicted_rating'])
    recommended_products = recommended_products.groupby('ma_san_pham', as_index=False).agg({'predicted_rating': 'max'})

    if rating is not None:
        recommended_products = recommended_products[recommended_products['predicted_rating'] >= rating]

    recommended_products = recommended_products.nlargest(top_n, 'predicted_rating')
    recommended_products['prediction_score'] = (recommended_products['predicted_rating'] / 5) * 100

    recommended_products = recommended_products.merge(
        df_products[['ma_san_pham', 'ten_san_pham', 'gia_ban', 'so_sao', 'mo_ta']].drop_duplicates(subset=['ma_san_pham']),
        on='ma_san_pham',
        how='left'
    )

    return recommended_products

# Hi·ªÉn th·ªã danh s√°ch s·∫£n ph·∫©m
def display_recommended_products(recommended_products, cols=5):
    for i in range(0, len(recommended_products), cols):
        columns = st.columns(cols)
        for j, col in enumerate(columns):
            if i + j < len(recommended_products):
                product = recommended_products.iloc[i + j]
                with col:
                    st.write(product['ten_san_pham'])
                    expander = st.expander(f"M√¥ t·∫£")
                    product_description = product['mo_ta']
                    truncated_description = ' '.join(product_description.split()[:100]) + '...'
                    expander.write(truncated_description)
                    expander.markdown("Nh·∫•n v√†o m≈©i t√™n ƒë·ªÉ ƒë√≥ng h·ªôp text n√†y.")

# Giao di·ªán ·ª©ng d·ª•ng
st.title("H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m - Collaborative Filtering")

# Th√™m t√πy ch·ªçn nh·∫≠p m√£ kh√°ch h√†ng
st.write("### Nh·∫≠p m√£ kh√°ch h√†ng ho·∫∑c ch·ªçn t·ª´ danh s√°ch:")
input_customer_id = st.text_input("Nh·∫≠p m√£ kh√°ch h√†ng (n·∫øu c√≥ th√¥ng tin m√£ kh√°ch h√†ng):", value="")

# Ch·ªçn ng·∫´u nhi√™n 50 m√£ kh√°ch h√†ng t·ª´ danh s√°ch
customer_ids = data_test['ma_khach_hang'].unique()
random_customer_ids = random.sample(list(customer_ids), min(50, len(customer_ids)))

# Dropdown ƒë·ªÉ ch·ªçn m√£ kh√°ch h√†ng
selected_customer_id_dropdown = st.selectbox(
    "Ho·∫∑c ch·ªçn m√£ kh√°ch h√†ng t·ª´ danh s√°ch:",
    options=[None] + random_customer_ids,  # Th√™m t√πy ch·ªçn None
    format_func=lambda x: f"M√£ kh√°ch h√†ng: {x}" if x else "Ch∆∞a c√≥ th√¥ng tin kh√°ch h√†ng"
)

# X√°c ƒë·ªãnh m√£ kh√°ch h√†ng cu·ªëi c√πng
if input_customer_id.strip():  # N·∫øu ng∆∞·ªùi d√πng nh·∫≠p m√£ kh√°ch h√†ng
    try:
        selected_customer_id = int(input_customer_id)  # Chuy·ªÉn ƒë·ªïi sang ki·ªÉu s·ªë nguy√™n
        if selected_customer_id not in customer_ids:
            st.warning("M√£ kh√°ch h√†ng b·∫°n nh·∫≠p kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng.")
            selected_customer_id = None
    except ValueError:
        st.error("M√£ kh√°ch h√†ng kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p s·ªë nguy√™n.")
        selected_customer_id = None
else:  # N·∫øu kh√¥ng nh·∫≠p, s·ª≠ d·ª•ng l·ª±a ch·ªçn t·ª´ dropdown
    selected_customer_id = selected_customer_id_dropdown

# Ch·ªçn s·ªë l∆∞·ª£ng s·∫£n ph·∫©m v√† m·ª©c ƒë√°nh gi√° t·ªëi thi·ªÉu
max_products = st.slider("Ch·ªçn s·ªë s·∫£n ph·∫©m t·ªëi ƒëa:", 1, 10, 5)
star_icons = ["‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê‚≠ê‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê"]
selected_min_rating = st.radio("Ch·ªçn m·ª©c ƒë√°nh gi√° t·ªëi thi·ªÉu:", star_icons)
min_rating = star_icons.index(selected_min_rating) + 1

# N√∫t g·ª£i √Ω
if st.button("G·ª£i √Ω s·∫£n ph·∫©m"):
    try:
        if selected_customer_id:
            # G·ª£i √Ω cho m√£ kh√°ch h√†ng ƒë∆∞·ª£c ch·ªçn
            recommendations = recommend_products_with_scores(
                customer_id=selected_customer_id,
                df_products=data_test,
                model=loaded_svd_pp,
                top_n=max_products,
                rating=min_rating
            )
        else:
            # G·ª£i √Ω m·∫∑c ƒë·ªãnh c√°c s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao
            recommendations = data_test[
                (data_test['so_sao'] >= 4) & (data_test['so_sao'] <= 5)
            ].drop_duplicates(subset='ma_san_pham').nlargest(max_products, 'so_sao')
            recommendations['prediction_score'] = (recommendations['so_sao'] / 5) * 100

        if recommendations.empty:
            st.warning("Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠ l·ªçc.")
        else:
            st.write("Danh s√°ch s·∫£n ph·∫©m ƒë∆∞·ª£c g·ª£i √Ω:")
            display_recommended_products(recommendations, cols=3)

    except Exception as e:
        st.error(f"L·ªói khi th·ª±c hi·ªán g·ª£i √Ω: {e}")























"""
import streamlit as st
import pandas as pd
import pickle
import os
import random

# T·∫£i d·ªØ li·ªáu
data_test = pd.read_csv('./df_summary_collaborative.csv')
df_products = pd.read_csv('./San_pham.csv')

# T·∫£i m√¥ h√¨nh SVD++
model_path = './svdpp_model.pkl'
if not os.path.exists(model_path):
    st.error("Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh SVD++. Vui l√≤ng ƒë·∫£m b·∫£o m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i 'model/svdpp_model.pkl'.")
else:
    with open(model_path, 'rb') as f:
        loaded_svd_pp = pickle.load(f)

# H√†m g·ª£i √Ω s·∫£n ph·∫©m d·ª±a tr√™n m√£ kh√°ch h√†ng
def recommend_products_with_scores(customer_id, df_products, data_test, model, top_n=4, rating=None):
    all_products = df_products['ma_san_pham'].unique()
    rated_products = df_products[df_products['ma_khach_hang'] == customer_id]['ma_san_pham'].unique()
    products_to_predict = [prod for prod in all_products if prod not in rated_products]

    recommendations = []
    for product_id in products_to_predict:
        prediction = model.predict(customer_id, product_id)
        recommendations.append((product_id, prediction.est))

    recommended_products = pd.DataFrame(recommendations, columns=['ma_san_pham', 'predicted_rating'])
    recommended_products = recommended_products.groupby('ma_san_pham', as_index=False).agg({'predicted_rating': 'max'})

    if rating is not None:
        recommended_products = recommended_products[recommended_products['predicted_rating'] >= rating]

    recommended_products = recommended_products.nlargest(top_n, 'predicted_rating')
    
    # Merge th√™m `gia_ban` v√† `ty_le_giam_gia` t·ª´ `data_test`
    recommended_products = recommended_products.merge(
        df_products[['ma_san_pham', 'ten_san_pham', 'gia_ban', 'so_sao', 'mo_ta']].drop_duplicates(subset=['ma_san_pham']),
        on='ma_san_pham',
        how='left'
    ).merge(
        data_test[['ma_san_pham', 'ty_le_giam_gia']].drop_duplicates(subset=['ma_san_pham']),
        on='ma_san_pham',
        how='left'
    )
    
    # X·ª≠ l√Ω t·ª∑ l·ªá gi·∫£m gi√° ƒë·ªÉ hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng ph·∫ßn trƒÉm
    recommended_products['ty_le_giam_gia'] = recommended_products['ty_le_giam_gia'] * 100
    recommended_products['ty_le_giam_gia'] = recommended_products['ty_le_giam_gia'].round(2)

    return recommended_products

# Hi·ªÉn th·ªã danh s√°ch s·∫£n ph·∫©m
def display_recommended_products(recommended_products, cols=3):
    for i in range(0, len(recommended_products), cols):
        columns = st.columns(cols)
        for j, col in enumerate(columns):
            if i + j < len(recommended_products):
                product = recommended_products.iloc[i + j]
                with col:
                    st.write(f"### {product['ten_san_pham']}")
                    st.write(f"Gi√°: **{product['gia_ban']:,} ƒë**")
                    st.write(f"ƒê√°nh gi√°: {'‚≠ê' * int(product['so_sao'])}")
                    st.write(f"Gi·∫£m gi√°: **{product['ty_le_giam_gia']}%**")
                    expander = col.expander("Xem m√¥ t·∫£ s·∫£n ph·∫©m")
                    expander.write(product['mo_ta'])

# Giao di·ªán ·ª©ng d·ª•ng
st.title("H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m - Collaborative Filtering")

# Th√™m t√πy ch·ªçn nh·∫≠p m√£ kh√°ch h√†ng
st.write("### Nh·∫≠p m√£ kh√°ch h√†ng ho·∫∑c ch·ªçn t·ª´ danh s√°ch:")
input_customer_id = st.text_input("Nh·∫≠p m√£ kh√°ch h√†ng (n·∫øu c√≥ th√¥ng tin m√£ kh√°ch h√†ng):", value="")

# Ch·ªçn ng·∫´u nhi√™n 50 m√£ kh√°ch h√†ng t·ª´ danh s√°ch
customer_ids = data_test['ma_khach_hang'].unique()
random_customer_ids = random.sample(list(customer_ids), min(50, len(customer_ids)))

# Dropdown ƒë·ªÉ ch·ªçn m√£ kh√°ch h√†ng
selected_customer_id_dropdown = st.selectbox(
    "Ho·∫∑c ch·ªçn m√£ kh√°ch h√†ng t·ª´ danh s√°ch:",
    options=[None] + random_customer_ids,
    format_func=lambda x: f"M√£ kh√°ch h√†ng: {x}" if x else "Ch∆∞a c√≥ th√¥ng tin kh√°ch h√†ng"
)

# X√°c ƒë·ªãnh m√£ kh√°ch h√†ng cu·ªëi c√πng
if input_customer_id.strip():
    try:
        selected_customer_id = int(input_customer_id)
        if selected_customer_id not in customer_ids:
            st.warning("M√£ kh√°ch h√†ng b·∫°n nh·∫≠p kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng.")
            selected_customer_id = None
    except ValueError:
        st.error("M√£ kh√°ch h√†ng kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p s·ªë nguy√™n.")
        selected_customer_id = None
else:
    selected_customer_id = selected_customer_id_dropdown

# Ch·ªçn s·ªë l∆∞·ª£ng s·∫£n ph·∫©m v√† m·ª©c ƒë√°nh gi√° t·ªëi thi·ªÉu
max_products = st.slider("Ch·ªçn s·ªë s·∫£n ph·∫©m t·ªëi ƒëa:", 1, 10, 5)
star_icons = ["‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê‚≠ê‚≠ê tr·ªü l√™n", "‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê"]
selected_min_rating = st.radio("Ch·ªçn m·ª©c ƒë√°nh gi√° t·ªëi thi·ªÉu:", star_icons)
min_rating = star_icons.index(selected_min_rating) + 1

# N√∫t g·ª£i √Ω s·∫£n ph·∫©m
if st.button("G·ª£i √Ω s·∫£n ph·∫©m"):
    try:
        if selected_customer_id:
            recommendations = recommend_products_with_scores(
                customer_id=selected_customer_id,
                df_products=df_products,
                data_test=data_test,
                model=loaded_svd_pp,
                top_n=max_products,
                rating=min_rating
            )
        else:
            recommendations = data_test[
                (data_test['so_sao'] >= 4) & (data_test['so_sao'] <= 5)
            ].drop_duplicates(subset='ma_san_pham').nlargest(max_products, 'so_sao')
            recommendations['ty_le_giam_gia'] = round(recommendations['ty_le_giam_gia'], 2)

        if recommendations.empty:
            st.warning("Kh√¥ng c√≥ s·∫£n ph·∫©m n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠ l·ªçc.")
        else:
            st.write("Danh s√°ch s·∫£n ph·∫©m ƒë∆∞·ª£c g·ª£i √Ω:")
            display_recommended_products(recommendations)

    except Exception as e:
        st.error(f"L·ªói khi th·ª±c hi·ªán g·ª£i √Ω: {e}")

"""



==================================================================================


content base:


v1:

'''import pandas as pd
import streamlit as st
from gensim import models, similarities
import pickle
import random

# T·∫£i d·ªØ li·ªáu s·∫£n ph·∫©m
try:
    Product = pd.read_csv('./Product_clean.csv', encoding='utf-8')
except FileNotFoundError:
    st.error("Kh√¥ng t√¨m th·∫•y file 'Product_clean.csv'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n v√† th·ª≠ l·∫°i.")
    st.stop()

# T·∫£i dictionary v√† m√¥ h√¨nh TF-IDF
try:
    with open('./dictionary.pkl', 'rb') as file:
        dictionary = pickle.load(file)
    tfidf = models.TfidfModel.load('./tfidf.tfidfmodel')
    index = similarities.SparseMatrixSimilarity.load('./index.docsim')
except FileNotFoundError:
    st.error("Kh√¥ng t√¨m th·∫•y c√°c m√¥ h√¨nh ho·∫∑c dictionary. Vui l√≤ng ki·ªÉm tra file v√† th·ª≠ l·∫°i.")
    st.stop()

# T√πy ch·ªânh giao di·ªán Streamlit
st.title("Content-Based Filtering - H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m")

# H√†m hi·ªÉn th·ªã s·∫£n ph·∫©m
def display_products(products, cols=4):
    num_items = len(products)
    rows = (num_items + cols - 1) // cols
    for row in range(rows):
        cols_instances = st.columns(cols)
        for col_idx in range(cols):
            idx = row * cols + col_idx
            if idx < num_items:
                with cols_instances[col_idx]:
                    st.markdown(f"**{products[idx]['T√™n s·∫£n ph·∫©m']}**")
                    st.markdown(f"Gi√°: **{products[idx]['Gi√° b√°n']:,}** ƒë")
                    st.markdown(f"ƒê√°nh gi√°: **{products[idx]['ƒêi·ªÉm trung b√¨nh']}‚≠ê**")
                    st.markdown(f"Gi·∫£m gi√°: **{products[idx]['T·ª∑ l·ªá gi·∫£m gi√°']}%**")

# H√†m g·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch
def show_similar_products_gensim1(dataframe, index, selected_product_code=None, num_similar=4):
    if selected_product_code is None:
        st.warning("B·∫°n ch∆∞a ch·ªçn s·∫£n ph·∫©m n√†o ƒë·ªÉ g·ª£i √Ω.")
        return pd.DataFrame()

    selected_product = dataframe[dataframe['ma_san_pham'] == selected_product_code]
    if selected_product.empty:
        st.error(f"Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m v·ªõi m√£: {selected_product_code}")
        return pd.DataFrame()

    selected_product_content = selected_product.iloc[0]['content']
    kw_vector = dictionary.doc2bow(selected_product_content.lower().split())
    sim = index[tfidf[kw_vector]]

    sorted_sim_indices = sorted(range(len(sim)), key=lambda k: sim[k], reverse=True)
    seen_similarities = {}

    for idx in sorted_sim_indices:
        if dataframe.iloc[idx]['ma_san_pham'] == selected_product_code:
            continue

        similarity = sim[idx]
        similar_product = dataframe.iloc[idx]
        if similar_product['diem_trung_binh'] >= 3:
            seen_similarities[similarity] = {
                "T√™n s·∫£n ph·∫©m": similar_product['ten_san_pham'],
                "ƒêi·ªÉm trung b√¨nh": similar_product['diem_trung_binh'],
                "Gi√° b√°n": similar_product['gia_ban'],
                "T·ª∑ l·ªá gi·∫£m gi√°": f"{similar_product['ty_le_giam_gia'] * 100:.0f}",
            }
        if len(seen_similarities) == num_similar:
            break

    return pd.DataFrame(list(seen_similarities.values()))

# Trang m·∫∑c ƒë·ªãnh hi·ªÉn th·ªã Top 50 s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t
def view_top_50_products():
    st.markdown("### Top 50 s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t")
    high_rating_products = Product.sort_values(by="diem_trung_binh", ascending=False).head(50)
    high_rating_products['ty_le_giam_gia'] = high_rating_products['ty_le_giam_gia'] * 100  # Chuy·ªÉn ƒë·ªïi t·ª∑ l·ªá gi·∫£m gi√° th√†nh ph·∫ßn trƒÉm
    high_rating_products['ty_le_giam_gia'] = high_rating_products['ty_le_giam_gia'].round(0)  # L√†m tr√≤n 2 ch·ªØ s·ªë nguy√™n
    st.markdown(f"Hi·ªÉn th·ªã **{len(high_rating_products)}** s·∫£n ph·∫©m ƒë∆∞·ª£c ƒë√°nh gi√° cao nh·∫•t:")
    display_products(
        high_rating_products[["ten_san_pham", "diem_trung_binh", "gia_ban", "ty_le_giam_gia"]]
        .rename(
            columns={
                "ten_san_pham": "T√™n s·∫£n ph·∫©m",
                "diem_trung_binh": "ƒêi·ªÉm trung b√¨nh",
                "gia_ban": "Gi√° b√°n",
                "ty_le_giam_gia": "T·ª∑ l·ªá gi·∫£m gi√°",
            }
        )
        .to_dict("records"),
        cols=4,
    )

# Trang g·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch ng·∫´u nhi√™n
def recommend_by_product():
    st.markdown("### G·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch c√°c s·∫£n ph·∫©m c·ªßa Hasaki (50 s·∫£n ph·∫©m kh√°ch h√†ng xem qua)")
    
    # L·∫•y 50 s·∫£n ph·∫©m ng·∫´u nhi√™n
    random_products = Product.sample(50)
    selected_code = st.selectbox(
        "Ch·ªçn s·∫£n ph·∫©m mu·ªën h·ªá th·ªëng g·ª£i √Ω:",
        random_products['ma_san_pham'].values,
        format_func=lambda x: Product.loc[Product['ma_san_pham'] == x, 'ten_san_pham'].values[0]
    )
    n = st.slider("S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·ª£i √Ω:", 1, 10, 5)
    if st.button("G·ª£i √Ω"):
        similar_products_df = show_similar_products_gensim1(Product, index, selected_product_code=selected_code, num_similar=n)
        if not similar_products_df.empty:
            display_products(similar_products_df.to_dict('records'))
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p!")

# T√≠ch h·ª£p giao di·ªán
page_names_to_funcs = {
    "Hi·ªÉn th·ªã Top 50 s·∫£n ph·∫©m ƒë√°nh gi√° cao nh·∫•t": view_top_50_products,
    "G·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch c√°c s·∫£n ph·∫©m c·ªßa Hasaki (50 s·∫£n ph·∫©m kh√°ch h√†ng xem qua)": recommend_by_product,
}

# ƒê·∫∑t ch·∫ø ƒë·ªô m·∫∑c ƒë·ªãnh hi·ªÉn th·ªã Top 50 s·∫£n ph·∫©m ƒë√°nh gi√° cao nh·∫•t
selected_page = st.sidebar.radio("Ch·ªçn ch·∫ø ƒë·ªô g·ª£i √Ω", page_names_to_funcs.keys())
page_names_to_funcs[selected_page]()
'''





















'''
import pandas as pd
import streamlit as st
from gensim import models, similarities
import pickle
from time import time

# T·∫£i d·ªØ li·ªáu s·∫£n ph·∫©m
try:
    Product = pd.read_csv('./Product_clean.csv', encoding='utf-8')
except FileNotFoundError:
    st.error("Kh√¥ng t√¨m th·∫•y file 'Product_clean.csv'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n v√† th·ª≠ l·∫°i.")
    st.stop()

# T·∫£i dictionary v√† m√¥ h√¨nh TF-IDF
try:
    with open('./dictionary.pkl', 'rb') as file:
        dictionary = pickle.load(file)
    tfidf = models.TfidfModel.load('./tfidf.tfidfmodel')
    index = similarities.SparseMatrixSimilarity.load('./index.docsim')
except FileNotFoundError:
    st.error("Kh√¥ng t√¨m th·∫•y c√°c m√¥ h√¨nh ho·∫∑c dictionary. Vui l√≤ng ki·ªÉm tra file v√† th·ª≠ l·∫°i.")
    st.stop()

# T√πy ch·ªânh giao di·ªán Streamlit
st.title("Content-Based Filtering - H·ªá th·ªëng g·ª£i √Ω s·∫£n ph·∫©m")

# H√†m hi·ªÉn th·ªã s·∫£n ph·∫©m
def display_products(products, cols=4):
    num_items = len(products)
    rows = (num_items + cols - 1) // cols
    for row in range(rows):
        cols_instances = st.columns(cols)
        for col_idx in range(cols):
            idx = row * cols + col_idx
            if idx < num_items:
                with cols_instances[col_idx]:
                    st.markdown(f"**{products[idx]['T√™n s·∫£n ph·∫©m']}**")
                    st.markdown(f"Gi√°: **{products[idx]['Gi√° b√°n']:,}** ƒë")
                    st.markdown(f"ƒê√°nh gi√°: **{products[idx]['ƒêi·ªÉm trung b√¨nh']}‚≠ê**")
                    st.markdown(f"Gi·∫£m gi√°: **{products[idx]['T·ª∑ l·ªá gi·∫£m gi√°']}%**")

# H√†m g·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch
def show_similar_products_gensim1(dataframe, index, selected_product_code=None, num_similar=4):
    if selected_product_code is None:
        st.warning("B·∫°n ch∆∞a ch·ªçn s·∫£n ph·∫©m n√†o ƒë·ªÉ g·ª£i √Ω.")
        return pd.DataFrame()

    selected_product = dataframe[dataframe['ma_san_pham'] == selected_product_code]
    if selected_product.empty:
        st.error(f"Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m v·ªõi m√£: {selected_product_code}")
        return pd.DataFrame()

    selected_product_content = selected_product.iloc[0]['content']
    kw_vector = dictionary.doc2bow(selected_product_content.lower().split())
    sim = index[tfidf[kw_vector]]

    sorted_sim_indices = sorted(range(len(sim)), key=lambda k: sim[k], reverse=True)
    seen_similarities = {}

    for idx in sorted_sim_indices:
        if dataframe.iloc[idx]['ma_san_pham'] == selected_product_code:
            continue

        similarity = sim[idx]
        similar_product = dataframe.iloc[idx]
        if similar_product['diem_trung_binh'] >= 3:
            seen_similarities[similarity] = {
                "T√™n s·∫£n ph·∫©m": similar_product['ten_san_pham'],
                "ƒêi·ªÉm trung b√¨nh": similar_product['diem_trung_binh'],
                "Gi√° b√°n": similar_product['gia_ban'],
                "T·ª∑ l·ªá gi·∫£m gi√°": f"{similar_product['ty_le_giam_gia'] * 100:.0f}",
            }
        if len(seen_similarities) == num_similar:
            break

    return pd.DataFrame(list(seen_similarities.values()))

# H√†m t√¨m ki·∫øm s·∫£n ph·∫©m d·ª±a v√†o n·ªôi dung nh·∫≠p v√†o
def show_similar_products_input_gensim2(dataframe, index, input_product_name, num_similar=4):
    input_product_tokens = input_product_name.lower().split()
    kw_vector = dictionary.doc2bow(input_product_tokens)
    sim = index[tfidf[kw_vector]]

    sorted_sim_indices = sorted(range(len(sim)), key=lambda k: sim[k], reverse=True)
    seen_similarities = {}
    for idx in sorted_sim_indices:
        similarity = sim[idx]
        similar_product = dataframe.iloc[idx]
        similar_product_name = similar_product['ten_san_pham']
        similar_product_score = similar_product['diem_trung_binh']
        similar_product_discount = similar_product.get('ty_le_giam_gia', 0) * 100

        if similar_product_name.lower() != input_product_name.lower() and similar_product_score >= 3:
            seen_similarities[similarity] = {
                "T√™n s·∫£n ph·∫©m": similar_product_name,
                "ƒêi·ªÉm trung b√¨nh": similar_product_score,
                "Gi√° b√°n": similar_product['gia_ban'],
                "T·ª∑ l·ªá gi·∫£m gi√°": round(similar_product_discount, 0),
            }
        if len(seen_similarities) == num_similar:
            break

    return pd.DataFrame(list(seen_similarities.values()))

# Trang t√¨m ki·∫øm s·∫£n ph·∫©m theo t·ª´ kh√≥a nh·∫≠p v√†o
def search_by_input():
    st.markdown("### T√¨m ki·∫øm s·∫£n ph·∫©m d·ª±a v√†o n·ªôi dung nh·∫≠p")

    if "input_product_name" not in st.session_state:
        st.session_state["input_product_name"] = ""

    input_product_name = st.text_area(
        "Nh·∫≠p t√™n s·∫£n ph·∫©m b·∫°n mu·ªën t√¨m (ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ xem Top 50 s·∫£n ph·∫©m):",
        value=st.session_state["input_product_name"],
        key="input_product_name",
        height=100
    )
    num_similar = st.slider("S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·ª£i √Ω:", 1, 10, 5)

    if st.button("T√¨m ki·∫øm"):
        if not input_product_name.strip():
            view_top_50_products()
        else:
            similar_products_df = show_similar_products_input_gensim2(Product, index, input_product_name, num_similar)
            if not similar_products_df.empty:
                display_products(similar_products_df.to_dict("records"))
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m n√†o ph√π h·ª£p!")

# Trang hi·ªÉn th·ªã Top 50 s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t
def view_top_50_products():
    st.markdown("### Top 50 s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t")
    high_rating_products = Product.sort_values(by="diem_trung_binh", ascending=False).head(50)
    high_rating_products['ty_le_giam_gia'] = high_rating_products['ty_le_giam_gia'] * 100
    high_rating_products['ty_le_giam_gia'] = high_rating_products['ty_le_giam_gia'].round(0)
    st.markdown(f"Hi·ªÉn th·ªã **{len(high_rating_products)}** s·∫£n ph·∫©m ƒë∆∞·ª£c ƒë√°nh gi√° cao nh·∫•t:")
    display_products(
        high_rating_products[["ten_san_pham", "diem_trung_binh", "gia_ban", "ty_le_giam_gia"]]
        .rename(
            columns={
                "ten_san_pham": "T√™n s·∫£n ph·∫©m",
                "diem_trung_binh": "ƒêi·ªÉm trung b√¨nh",
                "gia_ban": "Gi√° b√°n",
                "ty_le_giam_gia": "T·ª∑ l·ªá gi·∫£m gi√°",
            }
        )
        .to_dict("records"),
        cols=4,
    )

# Trang g·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch ng·∫´u nhi√™n
def recommend_by_product():
    st.markdown("### G·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch c√°c s·∫£n ph·∫©m c·ªßa Hasaki (50 s·∫£n ph·∫©m kh√°ch h√†ng xem qua)")
    random_products = Product.sample(50)
    selected_code = st.selectbox(
        "Ch·ªçn s·∫£n ph·∫©m mu·ªën h·ªá th·ªëng g·ª£i √Ω:",
        random_products['ma_san_pham'].values,
        format_func=lambda x: Product.loc[Product['ma_san_pham'] == x, 'ten_san_pham'].values[0]
    )
    n = st.slider("S·ªë l∆∞·ª£ng s·∫£n ph·∫©m g·ª£i √Ω:", 1, 10, 5)
    if st.button("G·ª£i √Ω"):
        similar_products_df = show_similar_products_gensim1(Product, index, selected_product_code=selected_code, num_similar=n)
        if not similar_products_df.empty:
            display_products(similar_products_df.to_dict('records'))
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p!")

# T√≠ch h·ª£p giao di·ªán
page_names_to_funcs = {
    "Hi·ªÉn th·ªã Top 50 s·∫£n ph·∫©m ƒë√°nh gi√° cao nh·∫•t": view_top_50_products,
    "G·ª£i √Ω s·∫£n ph·∫©m t·ª´ danh s√°ch c√°c s·∫£n ph·∫©m c·ªßa Hasaki (50 s·∫£n ph·∫©m kh√°ch h√†ng xem qua)": recommend_by_product,
    "T√¨m ki·∫øm s·∫£n ph·∫©m b·∫±ng n·ªôi dung nh·∫≠p": search_by_input,
}

selected_page = st.sidebar.radio("Ch·ªçn ch·∫ø ƒë·ªô g·ª£i √Ω", page_names_to_funcs.keys())
page_names_to_funcs[selected_page]()
'''





============================
Launch page

'''import streamlit as st
import base64

# C·∫•u h√¨nh trang Streamlit
st.set_page_config(
    page_title="A Recommender System for Hasaki.vn",
    page_icon="üõí",
    layout="wide",
    initial_sidebar_state="expanded",
)

# T√πy ch·ªânh giao di·ªán sidebar
def set_sidebar_style():
    sidebar_style = '''
    <style>
    [data-testid="stSidebar"] {
        background: linear-gradient(-225deg, #5271C4 0%, #B19FFF 48%, #ECA1FE 100%);
        color: white;
    }
    </style>
    '''
    st.markdown(sidebar_style, unsafe_allow_html=True)

set_sidebar_style()

# H√†m ƒë·∫∑t h√¨nh n·ªÅn
def set_background_image(image_file):
    try:
        with open(image_file, "rb") as file:
            encoded_string = base64.b64encode(file.read()).decode()
        st.markdown(
            f"""
            <style>
            .stApp {{
                background-image: url(data:image/png;base64,{encoded_string});
                background-size: cover;
                background-repeat: no-repeat;
                background-attachment: fixed;
            }}
            </style>
            """,
            unsafe_allow_html=True
        )
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y file h√¨nh n·ªÅn: {image_file}")

# ƒê·∫∑t h√¨nh n·ªÅn
set_background_image("hasaki_background.jpg")

# Ti√™u ƒë·ªÅ ch√≠nh
st.markdown(
    '<h1 style="color:#CCFF00; text-align: center;">A Recommender System for Hasaki.vn üõí</h1>',
    unsafe_allow_html=True
)

# Danh s√°ch th√†nh vi√™n nh√≥m
def display_team_members(members):
    st.markdown('<h2 style="color:#CCFF00; text-align: center;">Th√†nh vi√™n nh√≥m:</h2>', unsafe_allow_html=True)
    for member in members:
        st.markdown(f'<div style="color:#CCFF00; font-size: 20px; text-align: center;">{member}</div>', unsafe_allow_html=True)

team_members = ["1. Phan Minh Hu·ªá", "2. Hu·ª≥nh Danh Nh√¢n"]
display_team_members(team_members)

# K·∫øt n·ªëi ho·∫∑c ƒëi·ªÅu h∆∞·ªõng
def add_navigation_button(link, text):
    st.markdown(
        f'<div style="text-align: center; margin-top: 30px;">'
        f'<a href="{link}" target="_blank" style="color: #FFF; font-size: 20px; text-decoration: none; background: #5271C4; padding: 10px 20px; border-radius: 10px;">{text}</a>'
        f'</div>',
        unsafe_allow_html=True
    )

add_navigation_button("https://hasaki.vn", "H√£y tham quan c√°c s·∫£n ph·∫´m tr√™n website c·ªßa ch√∫ng t√¥i t·∫°i ƒë√¢y: Hasaki.vn")
'''
